<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <title>Ridham's Blog</title>
  <link rel="stylesheet" href="/static/styles.css">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
</head>
<body>
  <header class="site-header">
    <div class="container">
      <h1 class="site-title">
        <a href="/">Encoding rabbithole</a>
      </h1>    
        <nav class="site-nav">
        
          <a href="/">Home</a>
        
          <a href="/posts/">Posts</a>
        
          <a href="/thoughts/">Thoughts</a>
        
          <a href="/notes/">Notes</a>
        
      </nav>
    </div>
  </header>
  <main class="container">
    <article class="post">
      <p>this is a chatgpt chat summarised , by chatgpt for my personal reference, </p>
<p>if you can understand this, ggwp 
â€œso utf-8 only has like 8 bits , so it can only represent 256 charecters?â€</p>
<p>No. 8 bits is the size of one byte, but UTF-8 lets a character use 1, 2, 3 or 4 bytes. That yields well over a million possible characters.</p>
<p>â€œwait, wont 2 bytes be utf 16 ?â€</p>
<p>A 2-byte sequence could be either (a) one UTF-16 code-unit or (b) a 2-byte UTF-8 character. The bit pattern tells which.</p>
<p>â€œthat means i can make every charecter using a utf8 block , why use a utf-16 block.â€</p>
<p>UTF-8 wins on file size for Western text; UTF-16 gives cheaper random-access by 16-bit units and is a bit smaller for pure CJK data. Windows, Java, .NET and browser DOMs already store text internally as UTF-16.</p>
<p>â€œso because of the block start address, utf -8 is not good for larger data, show me with an example how utf -16 solves it.â€</p>
<p>To reach character n in UTF-8 you may have to scan the variable-length bytes before it.
In UTF-16 most everyday characters are one fixed 16-bit slot, so their byte offset is simply index Ã— 2 (unless you hit a surrogate pair).</p>
<p>â€œwhat if ğŸ˜ƒ had come as the second charecter, then show meâ€</p>
<p>UTF-8 offsets shift by +3 extra bytes (ğŸ˜ƒ is 4 bytes vs. 1-byte ASCII).
UTF-16 offsets shift by +2 bytes (ğŸ˜ƒ is two 16-bit units), so later characters move less.</p>
<p>â€œthe byte offset for third charecter in utf-16 is 6 , it should have been 4?â€</p>
<p>Because ğŸ˜ƒ happens earlier and takes two 16-bit units, every following character starts 2 bytes later than the simple index Ã— 2 rule.</p>
<p>â€œwhat is a BMP? what is a code-unit index? and what is a code-point index?â€</p>
<p>BMP: the first Unicode plane (U+0000â€“U+FFFF).
Code-unit index: position counted in 16-bit chunks (UTF-16) or 8-bit chunks (UTF-8).
Code-point index: position counted in actual characters people see.</p>
<p>â€œso you are saying, 16 bits is good enough for most charecters? including kanji, mandarin , hindi , emojies everything?â€</p>
<p>One 16-bit unit covers every BMP script (Latin, Hindi, common CJK). Emoji and rare Han characters sit above U+FFFF and need two units.</p>
<p>â€œwhat is a surrogate pair? and wasent 16 bits advantage it is easier to jump to nth charecter ? wont surrogate pair screw it ?â€</p>
<p>A surrogate pair = two reserved 16-bit values (D800â€“DBFF + DC00â€“DFFF) that together store one character â‰¥ U+10000. They keep constant-time math for code-unit positions; libraries just keep a tiny side-table to map them back to character counts.</p>
<p>â€œwhat do you mean subtracts? how did we get to 20 bit numbers , did we add 4 bits randomly ?â€</p>
<p>For any code-point â‰¥ U+10000 you subtract 0x10000, giving a value 0â€¦0xFFFFF. That occupies exactly 20 bitsâ€”no bits added.</p>
<p>â€œhow is upper 0x3d, wont it be , 0xf603 is 16 bits not 20 bitsâ€</p>
<p>0xF603 is padded to 20 bits: 0000 1111 0110 0000 0011.
Upper 10 bits = 0x3D, lower 10 bits = 0x203.</p>
<p>â€œand why will you add it to 0xD800â€</p>
<p>Adding to 0xD800 (or 0xDC00) drops the 10-bit payload into a block reserved only for surrogates, so decoders instantly know what theyâ€™re looking at.</p>
<p>â€œso after 16bits, you use 20 bits and normalise it back to 16 bits?â€</p>
<p>We expand 20 bits into two 16-bit units (32 bits total). Nothing shrinks back to 16.</p>
<p>â€œbut 3D D8 03 DE is 16 bits. so you got it down to 16 bits while representing itâ€</p>
<p>Itâ€™s four bytes: 3D D8 (first unit) + 03 DE (second unit) = 32 bits.</p>
<p>â€œoh yes, i mean it is a 32 bit code, so you work with 20 bits and then expand it to 32 bits? and i am guessing it cannot be more than 20 bits now?â€</p>
<p>Correct. 20-bit payload â†’ stored in 32 bits. Unicode is permanently capped at plane 16, so 20 bits will always be enough.</p>
<p>â€œ20 bits gives me 2^20 possibilities, that covers everything? !!â€</p>
<p>Yes. Planes 1-16 have 1 048 576 slots (2Â²â°). Plane 0 adds another 65 536. Total Unicode capacity = 1 114 112 code-points.</p>
<p>â€œso this is how the counting goes â€¦ i have like 2^16+2^20 possibilites?â€</p>
<p>Exactly: 65 536 (BMP) + 1 048 576 (Supplementary) = 1 114 112.</p>
<p>HOW A SURROGATE PAIR IS BUILT (ğŸ˜ƒ = U+1F603)
1F603 â€“ 10000 = 0F603 â†’ 20-bit payload</p>
<p>Upper 10 bits = 0x3D, lower 10 bits = 0x203</p>
<p>High surrogate = D800 + 3D = D83D
Low surrogate = DC00 + 203 = DE03
Stored little-endian: 3D D8 03 DE (32 bits)</p>
<p>TOTAL CAPACITY
Plane 0 (BMP): 2Â¹â¶ = 65 536</p>
<p>Planes 1-16: 2Â²â° = 1 048 576</p>
<p>Overall limit: 1 114 112 code-points (Unicode stops at U+10FFFF)</p>
<p>Assigned so far: ~154 000 â†’ plenty of space left.</p>
<p>WHEN TO USE WHICH ENCODING
â€¢ UTF-8 â€” default for web, JSON, logs; smallest for English-heavy text; ASCII-compatible.
â€¢ UTF-16 â€” good if your engine already uses it (Windows, Java, .NET) or if your data is mostly Chinese/Japanese/Korean.
â€¢ UTF-32 â€” trivially simple (one 32-bit int per character) but twice the size of UTF-16 and four times ASCII.</p>
    </article>
    
  </main>
  <footer class="site-footer">
    <div class="container">
      <p>&copy; 2025 RasenRhino. No rights reserved </p>
    </div>
  </footer>
</body>
</html>